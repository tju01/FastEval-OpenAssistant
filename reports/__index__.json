[
    {"id": "bb305917-79d8-4758-a854-1a6b2afd90f7", "model_type": "chatml", "model_name": "OpenAssistant/llama2-70b-sft-v10", "benchmarks": ["mt-bench", "cot", "human-eval-plus"], "model_args": {"default_system_message": "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."}},
    {"id": "d4d0d6b2-c015-478f-9365-6768debaf47b", "model_type": "chatml", "model_name": "andreaskoepf/llama2-13b-megacode3-16000", "benchmarks": ["mt-bench", "cot", "human-eval-plus", "lm-evaluation-harness"], "model_args": {}},
    {"id": "badf0ca3-2baf-4c3d-968d-74de497a0d31", "model_type": "chatml", "model_name": "andreaskoepf/falcon-40b-megacode2", "benchmarks": ["mt-bench", "human-eval-plus", "cot"], "model_args": {}},
    {"id": "f1999319-f5ad-4237-b1ec-1bedd5efd14d", "model_type": "chatml", "model_name": "OpenAssistant/falcon-40b-megacode2-oasst", "benchmarks": ["mt-bench", "human-eval-plus", "cot"], "model_args": {}},
    {"id": "39fdafc0-2cbc-4c4a-aa0a-f78e83b2f187", "model_type": "chatml", "model_name": "andreaskoepf/llama2-13b-orcabest", "benchmarks": ["mt-bench", "cot", "human-eval-plus", "lm-evaluation-harness"], "model_args": {}},
    {"id": "f6150e06-265b-4823-b0fc-ab4aa67c5b8d", "model_type": "chatml", "model_name": "andreaskoepf/llama2-13b-megacode2-oasst", "benchmarks": ["mt-bench", "cot", "human-eval-plus", "lm-evaluation-harness"], "model_args": {}},
    {"id": "980ce5fc-e4e4-4a22-8abc-8b392e3fa209", "model_type": "chatml", "model_name": "andreaskoepf/llama2-13b-megacode2_min100", "benchmarks": ["mt-bench", "cot", "human-eval-plus", "lm-evaluation-harness"], "model_args": {}},
    {"id": "cf002320-6934-40e1-9b81-fcb2c8f5c3b1", "model_type": "chatml", "model_name": "andreaskoepf/llama2-7b-megacode2_min100", "benchmarks": ["mt-bench", "cot", "human-eval-plus", "lm-evaluation-harness"], "model_args": {}},
    {"id": "6023b93e-5f60-4461-a04e-6e8c12c46ffa", "model_type": "chatml", "model_name": "andreaskoepf/llama2-7b-oasst-baseline", "benchmarks": ["mt-bench", "cot", "human-eval-plus", "lm-evaluation-harness"], "model_args": {}},
    {"id": "b4e0b417-9d3c-4f14-92d4-6f8c824821b1", "model_type": "open-assistant", "model_name": "OpenAssistant/oasst-sft-7e3-llama-30b", "benchmarks": ["cot", "human-eval-plus", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "short_name": "Open-Assistant Llama-33B SFT-7e3", "num_params": "33B"},
    {"id": "3f780bb1-68b1-4d08-a2df-6249057587ad", "model_type": "open-assistant", "model_name": "OpenAssistant/llama-30b-sft-v8-2.5k-steps", "benchmarks": ["mt-bench", "human-eval-plus", "cot", "lm-evaluation-harness"], "model_args": {}, "short_name": "Open-Assistant Llama-33B SFT-8", "num_params": "33B"},
    {"id": "4c5d0d5a-d154-46d7-adfc-fad49ea900b1", "model_type": "open-assistant", "model_name": "OpenAssistant/llama2_13b_orcaoasst_v2_8k", "benchmarks": ["mt-bench", "human-eval-plus", "cot"], "model_args": {"default_system_message": "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."}},
    {"id": "1b8b1eb8-1de3-4d7c-817d-1194649e6177", "model_type": "open-assistant", "model_name": "OpenAssistant/llama2_13b_orcacode2_8k", "benchmarks": ["lm-evaluation-harness", "mt-bench", "human-eval-plus", "cot"], "model_args": {"default_system_message": "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."}},
    {"id": "72422057-a1a9-4661-92fb-3fd10bdeddbf", "model_type": "open-assistant", "model_name": "OpenAssistant/llama2-13b-orca-v2-8k-3166", "benchmarks": ["mt-bench", "human-eval-plus", "cot"], "model_args": {"default_system_message": "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."}},
    {"id": "3bfaba5d-ff85-4180-a6ba-58dad9c15d85", "model_type": "open-assistant", "model_name": "OpenAssistant/llama2_13b_orcaoasst_8k", "benchmarks": ["cot", "mt-bench", "human-eval-plus"], "model_args": {"default_system_message": "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."}},
    {"id": "6888e157-88db-4027-bcdf-d1fa4c988e50", "model_type": "open-assistant", "model_name": "OpenAssistant/llama2_13b_orcacode_8k", "benchmarks": ["mt-bench", "human-eval-plus", "cot"], "model_args": {"default_system_message": "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."}},
    {"id": "6b2420c2-76a4-4ffc-8bb3-3ec8b31fc97b", "model_type": "open-assistant", "model_name": "OpenAssistant/oasst-llama2-70b-1", "benchmarks": ["mt-bench", "human-eval-plus"], "model_args": {}},
    {"id": "eae57659-6854-4cf0-899a-757b24b9e24d", "model_type": "open-assistant", "model_name": "OpenAssistant/Llama-2-70b-oasst-1-200-3", "benchmarks": ["cot"], "model_args": {}},
    {"id": "03e37322-6aa9-43d7-9ff9-a44f7d0cf0a3", "model_type": "open-assistant", "model_name": "OpenAssistant/llama2-13b-orca-8k-3319", "benchmarks": ["lm-evaluation-harness", "mt-bench", "human-eval-plus", "cot"], "model_args": {"default_system_message": "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information."}},
    {"id": "3f6a4733-339b-4977-adb6-85c797976a1a", "model_type": "open-assistant", "model_name": "OpenAssistant/oasst-rlhf-3-llama-30b-5k-steps", "benchmarks": ["cot", "human-eval-plus", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "short_name": "Open-Assistant Llama-33B RLHF-3", "num_params": "33B"},
    {"id": "6c582905-5298-4028-8287-787ba9464170", "model_type": "wizard-lm", "model_name": "WizardLM/WizardLM-70B-V1.0", "benchmarks": ["lm-evaluation-harness", "mt-bench", "cot", "human-eval-plus"], "model_args": {}, "short_name": "WizardLM 70B V1.0", "url": "https://huggingface.co/WizardLM/WizardLM-70B-V1.0"},
    {"id": "03eaca63-56c7-4e89-9b82-eeb6457c726a", "model_type": "openchat-llama2-v1", "model_name": "Open-Orca/OpenOrcaxOpenChat-Preview2-13B", "benchmarks": ["lm-evaluation-harness", "mt-bench", "human-eval-plus", "cot"], "model_args": {}, "short_name": "OpenOrca x OpenChat - Preview2 - 13B", "url": "https://huggingface.co/Open-Orca/OpenOrcaxOpenChat-Preview2-13B"},
    {"id": "f8ffcb1c-8532-46f5-b945-ae829bf27204", "model_type": "stable-beluga", "model_name": "stabilityai/StableBeluga-13B", "benchmarks": ["lm-evaluation-harness", "cot", "mt-bench", "human-eval-plus"], "model_args": {"default_system_message": "You are Stable Beluga 13B, an AI that follows instructions extremely well. Help as much as you can. Remember, be safe, and don't do anything illegal."}, "short_name": "StableBeluga-13B", "url": "https://huggingface.co/stabilityai/StableBeluga-13B"},
    {"id": "6883299b-8de3-4980-ad39-45f945b754eb", "model_type": "alpaca-without-prefix", "model_name": "NousResearch/Nous-Hermes-Llama2-13b", "benchmarks": ["lm-evaluation-harness", "mt-bench", "human-eval-plus", "cot"], "model_args": {}, "short_name": "Nous-Hermes Llama-2 13B", "url": "https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b"},
    {"id": "04d3a878-ac70-4a40-a4d1-4d434de47e43", "model_type": "dolphin", "model_name": "ehartford/dolphin-llama-13b", "benchmarks": ["lm-evaluation-harness", "cot", "mt-bench", "human-eval-plus"], "model_args": {}, "url": "https://huggingface.co/ehartford/dolphin-llama-13b", "short_name": "Dolphin Llama 13B"},
    {"id": "beaa2c36-153c-4f63-9c5a-1395db65c958", "model_type": "stable-beluga", "model_name": "stabilityai/StableBeluga2", "benchmarks": ["mt-bench", "cot", "human-eval-plus"], "model_args": {"default_system_message": "You are Free Willy, an AI that follows instructions extremely well. Help as much as you can. Remember, be safe, and don't do anything illegal."}, "url": "https://huggingface.co/stabilityai/StableBeluga2", "short_name": "Stable Beluga 2", "num_params": "70B"},
    {"id": "f62b92a8-ba5c-42ac-9637-523e521cfa8b", "model_type": "llama2-chat", "model_name": "meta-llama/Llama-2-70b-chat-hf", "benchmarks": ["lm-evaluation-harness", "mt-bench", "cot", "human-eval-plus"], "model_args": {"tokenizer": "hf-internal-testing/llama-tokenizer"}, "url": "https://huggingface.co/meta-llama/Llama-2-70b-chat-hf", "short_name": "LLaMA-2 70B Chat"},
    {"id": "366d8f77-a86c-46d5-86ae-0b57223f10b4", "model_type": "llama2-chat", "model_name": "meta-llama/Llama-2-13b-chat-hf", "benchmarks": ["mt-bench", "lm-evaluation-harness", "cot", "human-eval-plus"], "model_args": {"tokenizer": "hf-internal-testing/llama-tokenizer"}, "url": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf", "short_name": "LLaMA-2 13B Chat"},
    {"id": "2e225076-3c34-4e03-bc74-f4375f4d2d49", "model_type": "llama2-chat", "model_name": "meta-llama/Llama-2-7b-chat-hf", "benchmarks": ["lm-evaluation-harness", "mt-bench", "cot", "human-eval-plus"], "model_args": {"tokenizer": "hf-internal-testing/llama-tokenizer"}, "url": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf", "short_name": "LLaMA-2 7B Chat"},
    {"id": "d08ed3dd-795a-4978-84fe-4286d2461a21", "model_type": "fastchat", "model_name": "lmsys/vicuna-33b-v1.3", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {"tokenizer": "hf-internal-testing/llama-tokenizer"}, "url": "https://huggingface.co/lmsys/vicuna-33b-v1.3", "short_name": "Vicuna 33B V1.3"},
    {"id": "35b42dc8-34ad-4233-98b0-1c4e420dc46a", "model_type": "fastchat", "model_name": "lmsys/vicuna-7b-v1.3", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {"tokenizer": "hf-internal-testing/llama-tokenizer"}, "url": "https://huggingface.co/lmsys/vicuna-7b-v1.3", "short_name": "Vicuna 7B V1.3"},
    {"id": "4cea59cd-33ac-4579-b832-cfd30e393108", "model_type": "chatml", "model_name": "mosaicml/mpt-7b-chat", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/mosaicml/mpt-7b-chat", "short_name": "MPT-7B-Chat"},
    {"id": "e094967a-23ee-4538-bae5-088b5d81e29e", "model_type": "base", "model_name": "mosaicml/mpt-30b", "benchmarks": ["lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/mosaicml/mpt-30b", "short_name": "MPT-30B"},
    {"id": "eb74c9e1-8836-4c3a-8f50-a25808d20eee", "model_type": "chatml", "model_name": "mosaicml/mpt-30b-chat", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/mosaicml/mpt-30b-chat", "short_name": "MPT-30B-Chat"},
    {"id": "98e2de77-2a90-4560-9e0a-e9e18f5d8356", "model_type": "openai", "model_name": "gpt-3.5-turbo-0613", "benchmarks": ["human-eval-plus", "mt-bench", "cot"], "model_args": {}, "short_name": "GPT-3.5-Turbo-0613", "num_params": "proprietary"},
    {"id": "0fe60bfa-64d2-45b6-a34a-d408789b5175", "model_type": "falcon-instruct", "model_name": "tiiuae/falcon-7b-instruct", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/tiiuae/falcon-7b-instruct", "short_name": "Falcon-7B-Instruct"},
    {"id": "8017018c-065b-49d1-a13d-df4d85658337", "model_type": "base", "model_name": "tiiuae/falcon-7b", "benchmarks": ["lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/tiiuae/falcon-7b", "short_name": "Falcon-7B"},
    {"id": "31a8c8a1-05bd-45d9-8ef3-981e7704344c", "model_type": "open-assistant", "model_name": "OpenAssistant/oasst-sft-1-pythia-12b", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/OpenAssistant/oasst-sft-1-pythia-12b", "short_name": "Open-Assistant Pythia-12B SFT-1"},
    {"id": "68263b05-9164-45d3-ae65-51f9fec5bd83", "model_type": "open-assistant", "model_name": "OpenAssistant/pythia-12b-sft-v8-7k-steps", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/OpenAssistant/pythia-12b-sft-v8-7k-steps", "short_name": "Open-Assistant Pythia-12B SFT-8"},
    {"id": "0bc02e0e-a875-4ffb-bfdb-6f815217a67f", "model_type": "alpaca-without-prefix", "model_name": "NousResearch/Nous-Hermes-13b", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {"tokenizer": "hf-internal-testing/llama-tokenizer"}, "url": "https://huggingface.co/NousResearch/Nous-Hermes-13b", "short_name": "Nous-Hermes-13B"},
    {"id": "e732cae9-ad05-438b-9eb9-5788c20b95f9", "model_type": "alpaca-with-prefix", "model_name": "WizardLM/WizardCoder-15B-V1.0", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/WizardLM/WizardCoder-15B-V1.0", "short_name": "WizardCoder-15B"},
    {"id": "e7b8ce19-80ea-4a51-93af-1771d4a0b8e7", "model_type": "open-assistant", "model_name": "OpenAssistant/oasst-sft-7-llama-30b", "benchmarks": ["cot", "human-eval-plus", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/OpenAssistant/oasst-sft-7-llama-30b-xor", "short_name": "Open-Assistant Llama-33B SFT-7", "num_params": "33B"},
    {"id": "7a527ed0-d38c-4727-b1e5-926d33bc69fe", "model_type": "base", "model_name": "tiiuae/falcon-40b", "benchmarks": ["lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/tiiuae/falcon-40b", "short_name": "Falcon-40B"},
    {"id": "b7b8331c-cfc2-47c0-8b93-f704842babc1", "model_type": "falcon-instruct", "model_name": "tiiuae/falcon-40b-instruct", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/tiiuae/falcon-40b-instruct", "short_name": "Falcon-40B-Instruct"},
    {"id": "8468efcd-9290-47ab-8111-fe07455317ce", "model_type": "open-assistant", "model_name": "OpenAssistant/falcon-40b-sft-top1-560", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560", "short_name": "Open-Assistant Falcon-40B SFT-Top1"},
    {"id": "4c715856-8605-48a9-9882-3d0e62e9d6bb", "model_type": "open-assistant", "model_name": "OpenAssistant/falcon-40b-sft-mix-1226", "benchmarks": ["human-eval-plus", "cot", "mt-bench", "lm-evaluation-harness"], "model_args": {}, "url": "https://huggingface.co/OpenAssistant/falcon-40b-sft-mix-1226", "short_name": "Open-Assistant Falcon-40B SFT-Mix"},
    {"id": "b4f51256-c00f-4342-892a-ba45d453180b", "model_type": "guanaco", "model_name": "timdettmers/guanaco-65b-merged", "benchmarks": ["human-eval-plus", "mt-bench", "cot", "lm-evaluation-harness"], "model_args": {"tokenizer": "TheBloke/guanaco-65B-HF"}, "url": "https://huggingface.co/timdettmers/guanaco-65b-merged", "short_name": "Guanaco-65B"},
    {"id": "f5fc94f2-511f-4f57-bb3b-69876e829cb1", "model_type": "openai", "model_name": "gpt-3.5-turbo-0301", "benchmarks": ["human-eval-plus", "cot", "mt-bench"], "model_args": {}, "short_name": "GPT-3.5-Turbo-0301", "num_params": "proprietary"},
    {"id": "a44327c1-50a9-462b-ba96-34266470bf1a", "model_type": "openai", "model_name": "gpt-4-0613", "benchmarks": ["cot", "mt-bench", "human-eval-plus"], "model_args": {}, "short_name": "GPT-4-0613", "num_params": "proprietary"}
]
